---
layout: post
title: Kaggle 入门一步一步记录
subtitle: 认真，坚持
author: Bin Li
tags: [Machine Learning, Competitions]
image: 
comments: true
published: true
---

为了不让手生，纯复现机器学习算法也蛮无聊的，想抽空也看看Kaggle上的比赛，当然，刚开始还是拿已经结束的比较经典的比赛来试试看吧！


## Titanic: Machine Learning from Disaster
先通过具体[比赛介绍](https://www.kaggle.com/c/titanic)了解一下题意，我们是要通过给定的数据预测一个人是否最后会在灾难中生存下来。

了解了题目之后，接下来就是要看数据了。

### 数据预处理
#### 认识数据
* 看有什么类型的数据，每种数据应该用什么方式整理，数值型看最大最小值，众数，平均数等，标签型的看一共有多少类，分布是如何的，还有就是variable transformation, normalization and etc.

我们在处理数据的时候，最好将训练数据集和测试数据集放到一起来进行，然后再分开来训练和测试模型。

| Variable<span class="Apple-tab-span" style="white-space:pre"></span> | Definition | Key | Type |
| :-: | :-: | :-: | :-: |
| survival | Survival | 0 = No, 1 = Yes | L |
| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd | L |
| sex | Sex | male, female | L |
| Age | Age  | in years | N |
| sibsp | # of siblings / spouses aboard the Titanic |  | N |
| parch | # of parents / children aboard the Titanic |  | N |
| ticket | Ticket number |  | L |
| fare | Passenger fare |  | N |
| cabin | Cabin number |  | L |
| embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton | L |
| PassengerId | PassengerId |  | L |
| name |  |  | L |


对于固定类别的属性我们用onehot编码，对于连续数值型的我们就要对其进行标准化。

t-SNE 是个啥？？


**Name**

针对名字来说，具体姓氏名谁好像没有太大的利用之处，我们可以从称呼（salutations）中看到区别，于是我们多加一列，将称呼补充进去。
		
		
		
		
		
		
		
	


**pandas.map()怎么用？**

pandas.map() is used to map values from two series having one column same. For mapping two series, the last column of the first series should be same as index column of the second series, also the values should be unique.


## 问题总结
* 如果文件太大不能用pd.read_csv来装咋办？
* 对于NaN的数据，我们要怎么办？
    * 通过平均数来填充
    * 众数填充
* heatmap 是起什么作用的？

## References
1. [如何在 Kaggle 首战中进入前 10%](https://dnc1994.com/2016/04/rank-10-percent-in-first-kaggle-competition/)
2. [使用sklearn做单机特征工程](https://www.cnblogs.com/jasonfreak/p/5448385.html)
3. [分分钟带你杀入Kaggle Top 1%](https://zhuanlan.zhihu.com/p/27424282)
4. [Learn Machine Learning](https://www.kaggle.com/dansbecker/learn-machine-learning)
5. [Titanic Competition from Kaggle](https://www.kaggle.com/rochellesilva/simple-tutorial-for-beginners)
6. [Suggest an easy level/start level competition](https://www.kaggle.com/getting-started/12606)
7. [Introduction to Ensembling/Stacking in Python](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python)
8. [All You Need is PCA (LB: 0.11421, top 4%)](https://www.kaggle.com/massquantity/all-you-need-is-pca-lb-0-11421-top-4)
9. [Tutorial: Accessing Data with Pandas](https://www.kaggle.com/sohier/tutorial-accessing-data-with-pandas)
10. [Data Preparation & Exploration](https://www.kaggle.com/bertcarremans/data-preparation-exploration)
11. [Data preparation for building models](https://www.kaggle.com/sirpunch/flatten-de-serialize-credits-data)
12. [Data Preparation for Sberbank](https://www.kaggle.com/optidatascience/data-preparation-for-sberbank)
13. [Titanic: score over 80% - part 1 data preparation](https://www.kaggle.com/ymlai87416/titanic-score-over-80-part-1-data-preparation)
14. [Titanic: score over 80% - part 2 model selection](https://www.kaggle.com/ymlai87416/titanic-score-over-80-part-2-model-selection)
15. [Titanic, a step-by-step intro to Machine Learning](https://www.kaggle.com/ydalat/titanic-a-step-by-step-intro-to-machine-learning)
16. [Introduction to Ensembling/Stacking in Python](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python)
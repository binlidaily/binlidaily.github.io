---
layout: post
title: Outline of Algorithms
subtitle:
author: Bin Li
tags: [Outline]
comments: true
published: true
---

In order to facilitate the search, I wrote this blog. I've collected all algorithms that I learned or want to learn in `Machine Learning`, `Deep Learning`, `Mathematics` and `Data Structure and Algorithms`. I hope I can improve my skills and knowledge in these area with writing the interpretation about these algorithms. 

## Theoretical Machine Learning
### Supervised Learning
* [Linear Regression](https://binlidaily.github.io/2018-06-03-regression/)
* [Logistic Regression](https://binlidaily.github.io/2017-10-03-Logistics-Regression/)
* [Decision Tree](https://binlidaily.github.io/2018-09-11-decision-tree/)
* [Adaboost](https://binlidaily.github.io/2018-10-29-adaboost/)
* [Gradient Boosting](https://binlidaily.github.io/2018-12-05-gradient-boosting/)
* [Xgboost](https://binlidaily.github.io/2018-10-29-xgboost/)
* [Random Forest](https://binlidaily.github.io/2018-12-11-random-forest/)
* [Linear Discriminant Analysis (LDA)](https://binlidaily.github.io/2018-08-30-linear-discriminant-analysis/)

### Unsupervised Learning
#### Clustering
* K-Means
* K-Medians
* Latent Dirichlet Allocation (LDA)

## Applied Machine Learning
### Feature Engineering
Feature Engineering include Feature Extraction and Feature Selection.
#### Feature Extraction
* Exploratory Data Analysis (EDA)

#### Feature Selection
* Feature Selection Methods

### Model Ensemble
* Model Ensemble Methods

## Deep Learning
### Image Classification
* VGG


### Object Detection
* SSD


## Mathematics
### Information Theory
* [Entropy](https://binlidaily.github.io/2018-10-23-information-theory/)

### Optimization
* [Gradient Descent](https://binlidaily.github.io/2018-04-24-gradient-descent/)
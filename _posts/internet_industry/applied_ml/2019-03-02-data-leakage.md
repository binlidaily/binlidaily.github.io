---
layout: post
title: Data Leakage
subtitle:
author: Bin Li
tags: [Machine Learning]
image: 
comments: true
published: true
---


在数据挖掘中，数据泄露（leakage）指的是：本来不应该出现在X里的、和目标y有关的数据，出现在了X中。如此一来，机器学习算法就会有好到不真实的表现。

Kaggle Wiki链接：[Leakage | Kaggle](http://link.zhihu.com/?target=https%3A//www.kaggle.com/wiki/Leakage)

6.1. 数据泄露的种类以及影响分析

测试集数据被泄露到训练集：过拟合，模型在现实中的表现远不如test accuracy；测试集失去意义。
正确的预测（y）被泄露到测试集：严重过拟合，训练出的模型毫无用处，比赛组织者的极大失败
未来的信息被泄露到过去：时间序列相关，现实中模型将无法有效根据过去情况预测未来。
模型可以获得一些不该获得的信息，比如和目标变量有较大关系的变量、现实里接触不到的变量。例子：y是“病人是否患有癌症”，但是X包括了“病人是否接受肿瘤切除手术”。
反向工程，去匿名化，去除数据集中的随机打乱操作，社会工程学。这种行为是数据比赛明令禁止的，而且在现实中也涉嫌侵犯隐私。例子：反向工程“随机的”用户编码，得出用户的真名。
第三方信息。例子：已知坐标，利用geocoder类型的服务推出所在城市；在预测金融市场时加入第三方的政策新闻的特征。
6.2. 有效发现和利用数据泄露

数据泄露可以分为两大类：

由于自己的疏忽，在交叉验证、训练过程中，产生的数据泄露。这种情况属于失误，应当尽量避免。
在数据竞赛中，找到了理论上不能使用（但是也没有明令禁止）的额外数据，从而提升分数。
避免第一种数据泄露的方法，可以参考kaggle的各类比赛。假设有大量数据，我们可以把未处理的数据分为训练集和测试集，其中，测试集包括Public LB和Private LB两部分。

在模型的训练、选择和交叉验证时，我们只能接触训练集。
在对自己的模型非常自信时，可以偶尔在Public LB上验证。
只有模型即将被用于正式商业用途时，才能看模型在Private LB上的表现。
交叉验证误差、public LB误差、private LB误差：如果后者的误差值显著高于前者，那么需要考虑过拟合或第一类数据泄露。

第二类的数据泄露，属于旁门左道。本质上，这相当于在模型训练阶段，干了数据收集阶段的工作。搜集原始数据，或是自己提供数据举办竞赛（试图避免他人利用数据泄露）时，可以参考这种思路。

文件夹的创造时间。
看似乱码的字符串（如各类id）可能有统计分布的规律。
地理位置信息：如果提供了坐标，则可反向地理编码，得出相关地理信息。
这类数据可能会导致过拟合。

## References
1. [机器学习特征工程实用技巧大全](https://zhuanlan.zhihu.com/p/26444240)


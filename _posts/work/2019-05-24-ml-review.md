---
layout: post
title: Review of Machine Learning Algorithms
subtitle: 
author: Bin Li
tags: [Machine Learning]
image: 
comments: true
published: true
---

　　按照一定的精简形式整理机器学习相关算法，为了能够快速回忆，也帮助自己再一次梳理一遍算法。

## 1. 天下没有免费的午餐
　　在机器学习领域，一个基本的定理就是“没有免费的午餐”。换言之，就是没有算法能完美地解决所有问题，尤其是对监督学习而言（例如预测建模）。当然，所选的算法必须要适用于你自己的问题，这就要求选择正确的机器学习任务。作为类比，如果你需要打扫房子，你可能会用到吸尘器、扫帚或是拖把，但你绝对不该掏出铲子来挖地。

## 2. 偏差和方差
　　**偏差**描述的是预测值（估计值）的**期望**与真实值之间的差距。偏差越大，说明越偏离真实数值。

$$
\text{Bias}[\hat{f}(x)]=E[\hat{f}(x)]-f(x)
$$

　　**方差**描述的是预测值的变化范围和离散程度，即离其期望值的距离。

$$
\text{Var}[\hat{f}(x)]=E\left[(\hat{f}(x)-E[\hat{f}(x)])^{2}\right]
$$

　　模型的**真实误差**则是偏差和方差的和：

$$
E\left[(y-\hat{f}(x))^{2}\right]=\text{Bias}[\hat{f}(x)]^{2}+\text{Var}[\hat{f}(x)]+\sigma^{2}
$$


## 线性回归（Linear Regression）
* 决策函数
    * $h(x) = x^T \hat{w}$
* 损失函数
    * 平方损失：$\hat{w}=\text{argmin}_{w} \sum_{x, y}\left(y-x^{T} w\right)^{2}$
* 优化算法
    * 解析解直接计算：$\hat { w } = \left( \gamma \mathbf { I } + X ^ { T } X \right) ^ { - 1 } X ^ { T } y$
    * 逆不存在可以用梯度下降：
        1. 输入 $X$, $y$, 初始化权重 $w_0$
        2. 计算损失函数对参数 $w$ 的偏导并迭代更新
        3. 达到最大迭代次数，或者损失降低到一定程度退出
* **优点**：
    * 实现简单，计算简单。
* **缺点**：
    * 不能拟合非线性数据。
    * 对异常值非常敏感。


## 逻辑斯特回归（Logistic Regression）
* 决策函数
    * $h(x) = {1\over{1+e^{-x^T w}}} = p$
* 损失函数
    * 交叉熵损失：$$\begin{aligned}
\hat{w} &= \text{argmin}_{w} ~J(w)\\
&= \text{argmin}_{w} ~ -{1\over{m}}\sum_{i=1}^m\left( y \ln p + \left(1 - y \right)\ln \left(1 - p \right) \right)
\end{aligned}$$
* 优化算法
    * 梯度提升算法：${\partial J \over \partial w} = -{1\over{m}} \sum_{i=1}^m\left( y_i - h(x_i)\right) x_i$
* 优点
* 缺点

## 支持向量机 (Support Vector Machines)
![-w618](/img/media/15612749231809.jpg)

![-w263](/img/media/15612749643713.jpg)

![-w117](/img/media/15612749922825.jpg)

![-w366](/img/media/15612750157391.jpg)

![-w337](/img/media/15612750342905.jpg)

![-w339](/img/media/15612750588158.jpg)

![-w402](/img/media/15612752677609.jpg)

![-w141](/img/media/15612753956158.jpg)

![-w334](/img/media/15612754029374.jpg)

![-w273](/img/media/15612754145383.jpg)

![-w212](/img/media/15612754478836.jpg)

![-w381](/img/media/15612767173872.jpg)

![-w196](/img/media/15612767258395.jpg)
![-w239](/img/media/15612767374694.jpg)


![-w509](/img/media/15612767473244.jpg)
![-w149](/img/media/15612767563019.jpg)

![-w323](/img/media/15612767637714.jpg)


## 技巧性问题
如何解决过拟合问题？
* 正则化

如何应对类别不平衡的问题？


## 算法表格汇总
<div align="center">
<div class="datatable-begin"></div>

| 算法 | 类型 | 是否支持多分类 | 决策函数 | 优化目标 | 求解算法 |
| :-: | :-: | :-: | :-: | :-: | :-: |
| Adaboost | 有监督<br/>判别模型<br/>非线性 | 不直接支持 | $\begin{array}{l}{F(\mathrm{x})=\sum_{t=1}^{T} \alpha_{t} f_{t}(\mathrm{x})} \\ {\operatorname{sgn}(F(\mathrm{x}))}\end{array}$ | $\min _{F} \mathrm{E}(\exp (-y F(\mathrm{x})))$ | 分阶段优化<br/>公式解  |
|  |  |  |  |  |  |

<div class="datatable-end"></div>
</div>

## References
1. [机器学习算法优缺点对比及选择（汇总篇）](https://zhuanlan.zhihu.com/p/46831267)
2. [机器学习面试](http://www.aomanhao.top/2018/09/04/机器学习面试精华/)
3. [贝叶斯思想以及与最大似然估计、最大后验估计的区别](https://blog.csdn.net/ljp812184246/article/details/51176227)
4. [我几乎面了所有知名公司的算法岗位](https://zhuanlan.zhihu.com/p/55698399)
---
layout: post
title: "基于支持向量机的交叉验证与参数选择研究"
author: "Bin Li"
tags: "tags"
comments: true
published: false
---


2.1.3 常用训练算法

### 块算法(chunking algorithm)

Chunking算法 [10] 的出发点是删除矩阵中对应 Lagrange乘数为零的行和列将不会影响最终的结 果。对于给定的样本，Chunking算法的目标是通过 某种迭代方式逐步排除非支持向量，从而降低训练 过程对存储器容量的要求。具体做法是，将一个大 型QP问题分解为一系列较小规模的QP问题，然后找 到所有非零的Lagrange乘数并删除。在算法的每步 中Chunking都解决一个QP问题，其样本为上一步所剩的具有非零Lagrange乘数的样本以及M个不满足 KKT条件的最差样本。如果在某一步中，不满足KKT 条件的样本数不足M个，则这些样本全部加入到新 的QP问题中。每个QP子问题都采用上一个QP子问 题的结果作为初始值。在算法进行到最后一步时， 所有非零Lagrange乘数都被找到，从而解决了初始 的大型QP问题。

Chunking算法将矩阵规模从训练样本数的平方 减少到具有非零Lagrange乘数的样本数的平方，在 很大程度上降低了训练过程对存储容量的要求。 Chunking算法能够大大提高训练速度，尤其是当支 持向量的数目远远小于训练样本的数目时。然而， 如果支持向量个数比较多，随着算法迭代次数的增 多，所选的块也会越来越大，算法的训练速度依旧 会变得十分缓慢。

如块算法、Osuna 方法、SVMlight、SMO算法、Generalized Decomposition Algorithm算法、GSMO 算法。

### 分解算法（decomposition algorithm）

分解算法最早在文献[11]中提出，是目前有效解决大规模问题的主要方法。分解算法将二次规划问题分解成一系列规模较小的二次规划子问题，进行迭代求解。在每次迭代中，选取拉格朗日乘子分量的一个子集做为工作集，利用传统优化算法求解一个二次规划的子问题。以分类SVM为例，分解算法的主要思想是将训练样本分成工作集B和非工作集N，工作集B中的样本个数为q，q远小于训练样本总数。每次只针对工作集B中的样本进行训练，而固定N中的训练样本。该算法的关键在于选择一种最优工作集选择算法，而在工作集的选取中采用了随机的方法，因此限制了算法的收敛速度。

文献[12]在分解算法的基础上对工作集的选择做了重要改进。采用类似可行方向法的策略确定工作集B。如果存在不满足KTT条件的样本，利用最速下降法，在最速下降方向中存在q个样本，然后以这q个样本构成工作集，在该工作集上解决QP问题，直到所有样本满足KTT条件。如此改进提高了分解算法的收敛速度，并且实现了SVMlight算法。

文献[13]提出的序列最小优化(sequential minimal optimization，SMO)算法是分解算法的一个特例，工作集中只有2个样本，其优点是针对2个样本的二次规划问题可以有解析解的形式，从而避免多样本情况下的数值解不稳定及耗时问题，且不需要大的矩阵存储空间，特别适合稀疏样本。工作集的选择不是传统的最陡下降法，而是启发式。通过两个嵌套的循环寻找待优化的样本，然后在内环中选择另一个样本，完成一次优化，再循环，进行下一次优化，直到全部样本都满足最优条件。SMO算法主要耗时在最优条件的判断上，所以应寻找最合理即计算代价最低的最优条件判别式。

SMO算法提出后，许多学者对其进行了有效的改进。文献[14]提出了在内循环中每次优化3个变量，因为3个变量的优化问题同样可以解析求解，实验表明该算法比SMO的训练时间更短。文献[15-16]在迭代过程中的判优条件和循环策略上做了一定的修改，加快了算法的速度。

### 增量算法(incremental algorithm)
增量学习是机器学习系统在处理新增样本时，能够只对原学习结果中与新样本有关的部分进行增加修改或删除操作，与之无关的部分则不被触及。增量训练算法的一个突出特点是支持向量机的学习不是一次离线进行的，而是一个数据逐一加入反复优化的过程。

文献[17]最早提出了SVM增量训练算法，每次只选一小批常规二次算法能处理的数据作为增量，保留原样本中的支持向量和新增样本混合训练，直到训练样本用完。文献[18]提出了增量训练的精确解，即增加一个训练样本或减少一个样本对Lagrange系数和支持向量的影响。文献[19]提出了另一种增量式学习方法，其思想是基于高斯核的局部特性，只更新对学习机器输出影响最大的Lagrange系数，以减少计算复杂度。文献[20]提出了一种“快速增量学习算法”，该算法依据边界向量不一定是支持向量，但支持向量一定是边界向量的原理，首先选择那些可能成为支持向量的边界向量，进行SVM的增量学习，找出支持向量，最终求出最优分类面，提高训练速度。文献[21]提出了基于中心距离比值的增量运动向量机，利用中心距离比值，在保证训练和测试准确率没有改变的情况下，提高收敛速度。文献[22]提出了基于壳向量的线性SVM增量学习算法，通过初始样本集求得壳向量，进行SVM训练，得到支持向量集降低二次规划过程的复杂度，提高整个算法的训练速度和分类精度。

---

## 交叉验证
交叉验证是又一种模型选择方法，它与前面介绍的模型选择方法有所不同，是一种没有任何前提假定直接估计泛化误差的模型选择方法，由于没有任何假定，可以应用于各种模型选择中，因此具有应用的普遍性，又由于其操作的简便性，被人们认为是一种行之有效的模型选择方法。这一章我们将介绍交叉验证的基本原理接着会去定义不同交叉验证的过程，交叉验证提出一个比较好的评估性能。

### 交叉验证的思想
交叉验证的产生是一个曲折的过程，首先是人们发现用同一数据集既进行模型训练又进行泛化误差的估计会产生一个较差的结果，也就是我们常说的训练误差估计的乐观性，为了克服这个问题，交叉验证的方法被人们提了出来，它的基本思想是将数据分为两部分，一部分数据用来进行模型的训练，通常我们叫做训练集，另一部分数据用来测试训练生成模型的误差，我们叫做测试集，由于两部分数据的不同，泛化误差的估计是在新的数据上进行，这样的泛化误差的估计可以更接近真实的泛化误差，在数据足够的情况下，我们可以很好估计出真实的泛化误差，但是在实际应用中，往往只有有限的数据可用，我们必须对数据进行重用，对数据进行多次切分来得到好的估计，自从交叉验证提出以后，人们提出了不同的数据切分方式，因此产生了多种形式的交叉验证方法，下面我们对主要的交叉验证方法作一个详细的介绍。

在大多数实际应用中，只有有限的数据是可用的，这导致分裂数据的想法：部分数据（训练样本）用于训练算法，并且使用剩余数据（验证样本） 用于评估算法的性能。只要数据是独立同分布，验证样本就可以扮演“新数据”的角色。

单个数据分割产生对风险的验证估计，而对多个分割进行平均得到交叉验证估计。交叉验证的主要兴趣在于数据分裂启发式的普遍性。 它只假定数据是相同分布的，训练和验证样本是独立的，甚至可以放宽（见第8.1节）。 因此，CV可应用于（几乎）任何框架中的几乎任何算法，如回归（Stone，1974; Geisser，1975），密度估计（Rudemo，1982; Stone，1984）和分类（Devroye和Wagner ，1979; Bartlett等，2002）等等。 大多数其他模型选择程序（参见第3节）并不具备这种普遍性，这些程序往往是特定的框架，在另一个框架中可能会完全误导。 例如，C p（Mallows，1973）是特定的最小二乘回归。


### 交叉验证的方法
在本节中，风险的保留（或验证）估计被定义，接着引出我们对的一般定义。

比较常用的如下几种交叉验证的方法：


hold-out[8]: 最早由Devroye和Wagner在1979年提出，主要思想是将数据集进行一次切分，一部分用来训练模型，另一部分用来测试，这是最简单的一种方法，也是交叉验证的雏形。下面我们用数学语言进行描述，通常设 $I^t$ 为集合见 $D_n={\{1,\cdot \cdot \cdot, n\}}$ 的非空子集合，$I^v={(I^t)}={\{1,\cdots, n\}}$ 为其补集，我们用 $I^t$ 作为训练集来进行模型训练，$I^v$ 作为测试集来进行泛化误差的估计，这种方法通常只对数据集进行一次随机切分，训练生成的模型用 $A(D_n)$ 表示，最后泛化误差的估计为

$$ \hat{R}_{HO}(A;D_n;I^i) = {1\over{n_v}}{\Sigma_{i\in{D_n^v}}L(A(D_n);\xi_i)} $$

![](/images/media/15208399461745.jpg)

Geisser（1975）给出了CV策略的一般描述：简而言之，CV包括对相应于不同数据拆分的风险进行平均的几个保留估计。
![](/images/media/15208400328559.jpg)

![](/images/media/15208402247378.jpg)

#### 历史评论
简单验证是第一个类似CV的过程。 它被引入心理学领域（Larson，1931），因为需要一个可靠的替代重构替代错误的方法，正如Anderson等人所说的。（1972年）。 Herzberg（1969）使用它来评估预测因子的质量。 Stone（1974）首先考虑选择训练集的问题，其中“可控”和“不可控”数据分裂是有区别的。

## 参数选择
### 模型参数的影响
参数是机器学习算法的关键，它们是从训练数据中学习的模型的一部分。机器学习模型中一般分两类参数，一个是模型参数（model parameters），另一个是模型超参数（model hyperparameter）。模型参数是模型内部的配置变量，其值可以根据数据进行估计。在经典的机器学习文献中，我们可以将模型看作假设，将参数视为对特定数据集的假设进行裁剪。模型参数从数据中学习到，保存作为模型的一部分，其值决定了模型的能力，且在模型做预测时起作用。模型超参数是模型外部的配置，其值无法从数据中估计。我们无法知道给定问题的模型超参数的最佳值。 我们可以使用经验法则，在其他问题上使用相同的值，或通过反复试验来搜索最佳值。当机器学习算法针对特定问题进行调整时（例如，当使用网格搜索或随机搜索时），那么正在调整模型的超参数或顺序以得到最熟练的模型的参数预测。

在训练支持向量机时，我们更多需要关注的是模型超参，即模型的惩罚系数C。经分析对支持向量机有着重要影响的参数是:惩罚因子C，核函数及其参数的选取。惩罚因子C用于控制模型复杂度和逼近误差的折中，C越大则对数据的拟合程度越高,学习机器的复杂度就越高，容易出现“过学习”的现象。而C取值过小，则对经验误差的惩罚小，学习机器的复杂度低，就会出现“欠学习”的现象。当C的取值大到一定程度时，SVM模型的复杂度将超过空间复杂度的最大范围，那么当C继续增大时将几乎不在对SVM的性能产生影响。

### 模型参数选择的方法
**穷举法**
所谓穷举法就是在支持向量机模型确定以后，先根据经验对其惩罚因子C和核函数固有参数进行初始化赋值，然后通过实验测试，再根据测试数据反复调整参数值，直到得到满意的结果为止。实验表明，随着C的增加，分类精度迅速提高，但是继续增加C，性能的变化并不明显，当C的值足够大的时候，模型的性能将不再随着C的变化而变化了。通过分析我们可以知道，当C开始增加，模型的复杂度随之增加，支持向量的个数随之减少，而处于边界的支持向量则迅速减少。而当C的值足够大的时候，模型中边界支持向量的数量为0的时候，C的变化就不会再影响模型的性能。

穷举法是目前使用最为广泛的参数选择方法之一，其操作简单而有效。但是其对参数的调整完全凭借经验，缺乏足够的理论依据。该方法对于不同数量的样本，不同的核函数来说，其调整方法都可能是不同的，特别是当调整幅度比较大以及核函数参数比较多的时候，调整将会变得比较复杂。

**交叉验证法**
所谓交叉验证法就是指在训练SVM模型开始之前，对其训练数据进行一部分保留，然后利用这部分数据对训练后的模型进行评估。一般比较常用的是K折交叉验证法（K-foldcrossvalidation）。首先，将训练数据平均分成K组，然后取出其中一组进行保留，然后使用剩下的K-1组进行训练构建模型，最后用保留下的一组对训练出来的模型进行评估检测。将以上过程重复K次，保证每组数据都被保留测试过，然后根据K次评估检测得到的值来估计期望泛化误差，以此选择最优的参数。

交叉验证法是统计学习中的著名方法，被称为对泛化误差的无偏估计，它能够有效的防止过学习现象。它既具有一定的训练精度，又获得良好的泛化性能。目前该方法使用广泛，但是如果参数较多该方法将耗费大量时间，而且计算量大也是其缺点之一。

**梯度下降法**

2002年，Chapelle[3]等提出了一种采用梯度下降法、通过最小化一般错误的分解上界实现SVM参数的自动选择。梯度下降法，就是利用负梯度方向来决定每次迭代的新的搜索方向，使得每次迭代能使待优化的目标函数逐步减小。其公式如下所示：
![](/images/media/15209054203776.jpg)

其中a为称为学习速率，可以是较小的常数。gn是xn的梯度。使用梯度下降法来对SVM参数进行选择首先需要根据经验确定一组参数，作为梯度下降法的初始点，然后再使用梯度下降法寻找最佳参数。

虽然该算法在计算时间上比之交叉验证法和试凑法有了明显改善，但是梯度下降法对初始点要求较高，而且是一种线性搜索法，因此极易陷入局部最优。

**网格搜索算法**

2003年，Hsu,Chang,和Lin[4]提出使用网格搜索算法，求SVM惩罚因子和RBF核参数的最优解。网格搜索法是目前比较常用的。

数据搜索方法之一，对于RBF核SVM模型来说，其算法流程如下所示：首先，对于惩罚因子C和RBF核参数gamma分别确定其取值范围和搜索步长，从中得到M个C的值以及N个gamma的值。然后，根据M个C和N个gamma构建M*N组不同参数，使用每个参数构建SVM模型得到分类精度，以此确定最优的参数组C和gamma。

最后，如何最佳分类精度依然没有达到要求，就可以根据分类精度曲线重新选择取值范围和搜索步长，进行细搜索直到满足要求为止。

网格搜索法的优点就是可以对多个参数同时进行搜索，参数之间相互联系相互制约的关系，使其能够更好更快的得到最优解。而MxN组参数之间则是相互独立，这使得其可以进行并行搜索提高运算效率。其缺点就是当参数比较多时，如多项式核参数有3个，再加上惩罚因子C，也就是说对于多项式核SVM模型来说，需要对4个参数同时进行选择，假设4个参数的取值个数分别为M,N,P,Q,那么使用网格搜索法将计算MxNxPxQ组参数，计算量巨大。

**基于遗传算法的SVM模型参数选择**

通过分析，我们可以知道SVM模型的参数选择问题就是一个优化搜索问题。而遗传算法本身就是一种被广泛应用的随机搜索优化算法。遗传算法本身具有很强的鲁棒性，不依赖于问题的具体领域。强大的全局搜索能力和可并行性使其能够快速有效的搜索到全局最优解。因此使用遗传算法对SVM模型参数进行选择是可行的。其算法流程如下所示：

首先，选择SVM模型的核函数并确定惩罚因子C和核参数的编码方式和染色体结构。根据染色体结构设计和构建遗传算法的选择，交叉，变异等算子。

其次，随机产生染色体的初始种群，并对种群中的所有染色体进行解码，每个染色体就是一组参数。

然后，使用每组参数训练SVM分类模型并使用该模型对测试数据进行测试，得到其识别率。将该识别率作为参数所对应的染色体的适应度值。

最后，判断种群中最优适应度值是否达到要求，如果是，则将最优适应度所对应的染色体进行解码得到最优参数组，否则，开始遗传操作，对种群进行选择，交叉，变异等操作得到新一代的种群。

Chen[5]和Zheng[6]采用不同的推广能力估计作为遗传算法的适应度函数，提出了两种基于遗传算法的SVM模型参数优化方法，结果表明利用遗传算法对SVM参数进行优选不仅缩小了计算时间，而且还降低了对初始值选取的依赖度。

**基于粒子群算法的SVM模型参数选择**

2006年，Lee和Cho[7]提出使用粒子群算法用于求解SVM参数优化问题。粒子群优化PSO(Particle Swarm Optimization)算法是一种新兴的基于种群智能的随机全局优化算法，通过种群中粒子间的合作与竞争产生的群体智能指导优化搜索，与进化算法比较，PSO算法保留了基于种群的全局搜索策略，采用简单的速度位移模型，避免了复杂的杂交、遗传和变异等操作整个粒子群算法中体现了粒子在寻找食物源(最优解)中既保持自身惯性，又利用个体认知和社会认知不断修改自身飞行方向，最终导致群体朝食物源靠近。

PSO算法首先随机产生n组参数作为初始粒子群，然后通过迭代找到最优解，在每一次迭代中粒子通过个体最优解和群体最优解两个值来更新自己，使得整个种群朝着最优解的方向进化。

为了更具有普遍意义，在本研究中我们将重点研究以常用的Grid Search的方法来进行参数选择。

## 第三章 基于 Alpha Seeding 的支持向量机交叉验证优化
### 3.1 算法推导前期基础
在前一章我们介绍了支持向量机的数学基本公式，在序列最小优化算法的算法中，训练实例$x_i$与如下定义的最优性指标$f_i$相关联。
![](/images/media/15209477179442.jpg)

SVM训练的最优性条件是KarushKuhn-Tucker（KKT）（Kuhn，2014）条件。 当满足最优条件时，我们有最优指标满足以下约束条件。

![](/images/media/15209483089391.jpg)

其中
![](/images/media/15209483233470.jpg)

正如Keerthi等人所观察到的那样。 （Keerthi et al.2001），约束条件（3）等价于下面的约束条件。
![](/images/media/15209483599791.jpg)

其中b是超平面的偏差，我们在接下来的章节中提出的算法会利用到这个约束条件。

k折交叉验证将数据集均匀分成k个子集。 一个子集被用作测试集合T，而其余（k-1）个子集合一起形成训练集合X.假设我们已经使用第一到第（h-1）训练了第h个SVM（在第h轮） ）和第（h + 1）到第k个子集作为训练集，第h个子集作为测试集（参见图1b）。 现在我们要训练第（h + 1）个SVM。 然后，在两轮训练之间共享第1至第（h-1）子集和第（h + 2）至第k子集。 为了将第h轮中使用的训练集转换为第（h + 1）轮的训练集，我们只需从第（h + 1）个子集中删除并将第h个子集添加到所使用的训练集 在第h轮。 此后，我们分别将第h和第（h + 1）个SVM称为先前的SVM和下一个SVM。

为便于表示，我们用S表示共享子集（k-2）子集，用S表示前一轮训练中的非共享子集R，并表示前一轮测试子集T。 让我们继续使用图1所示的例子，S由第1到第（h-1）个子集和第（h + 2）到第k个子集组成; R是第（h + 1）子集; T是第h个子集。 为了将第h轮中使用的训练集X转换为训练集X？ 对于第（h + 1）轮，我们只需要从X中删除R并将T加到X，即X？ =T∪X\ R =T∪S。 我们分别用I R，I T和I S表示如下对应于R，T和S的三组索引。

![](/images/media/15209494880266.jpg)

两轮k次交叉验证通常具有许多共同的训练实例，如这里的S集合的样本。 当k是10时，X和X中有9 8（或〜90％）的实例？ 是S的实例。接下来，我们研究了三个重用先前的SVM的算法来训练下一个SVM。

我们提出了三种算法，它们重复使用先前的SVM来训练下一个SVM，我们逐渐地将一种算法依次重新定义。 （i）我们的第一种算法旨在初始化α值α？基于前一个SVM的α值α，将其转化为下一个SVM的最优值。我们将第一种算法称为调整阿尔法最佳值（ATO）。 （ii）为了有效地初始化α？ ，我们的第二个算法保持S中实例的α值不变（即对于s∈IS，αs？=αs），并估计αt？对于t∈IT。该算法通过在问题（1）的约束下将R替换为T来有效地执行α值初始化，因此我们称之为多重实例替换（MIR）算法。 （iii）与MIR相似，我们的第三种算法也保持S中实例的alpha值不变;与MIR不同，该算法一次将T中的实例替换为T中的实例，这大大缩短了初始化α的时间？ 。我们称之为第三种算法单实例替换（SIR）。接下来，我们详细阐述这三种算法。



### 3.2 权重 Alpha 调优方法
第一种算法我们直接调整alpha值到最优（Alpha Towards Optimum, ATO），ATO旨在将alpha值初始化为最佳值。 它采用由Karasuyama和Takeuchi（Karasuyama和Takeuchi 2009）设计的在线SVM训练技术进行k次交叉验证。 在在线SVM训练中，从训练组X中去除过时训练实例的子集R，即X？ = X \ R; 将新到达的训练实例的子集T添加到训练集中，即X？ = X？ ∪T。 先前使用X训练的SVM通过移除和添加实例的子集来调整，以获得下一个SVM。

在ATO算法中，我们首先构造一个新的训练数据集X？ 其中X？ = S = X \ R然后，我们逐渐？ 增加T中实例的α值（即对于t∈IT增加αt），用αT表示。 ，（接近）它们的最佳值;同时，我们逐渐减少R中实例的α值（即对于r∈IR，减少αr？），用αR？表示。 一旦T中实例的α值满足最优条件（即约束（5）），我们将实例从T移动到训练集X？; 类似地，一旦R中的实例的α值等于0（成为非支持向量），我们从R中移除实例。当R为空时，ATO终止α值初始化。

接着我们就要更新alpha的权值了，接下来，我们介绍一下增加αT的细节。 并减少αR？。 我们用αT表示增量的步长大小？ 并在αR上递减？ 由η表示。 从问题（1）的约束中，所有的alpha值必须在？ [0，C]。 因此，对于t∈IT是αt的增量，记为Δαt？ ，不能超过（C - αt？）; 对于r∈IR的递减？？？ αr表示为Δαr，不能超过αr。 我们用ΔαT表示T中所有实例的α值的变化。 并且R中实例的所有α值由ΔαR变化？。 那么，我们可以计算ΔαT？ 和ΔαR？ 如下。
![](/images/media/15209519788688.jpg)

其中1是所有维度都为1的向量。当我们加上ΔαT？ 到αT？ 和ΔαR？ 到αR？ 问题（1）的约束必须满足。 但是，调整αT后？ 和？？ αR？ ，我们需要调整X中的训练实例的alpha值。 （回想一下，在这个阶段X = S）。 我们建议调整X中训练实例的alpha值？ 这也在M中，其中x i∈M，给定i∈Im。 总之，增加αT后？ 并减少αR？ ，我们调整αM？。 所以当调整αT？ ，αR？ 和αM？ ，根据问题（1）的约束，我们有下面的等式。

![](/images/media/15209562607324.jpg)

M通常具有大量的实例，并且有许多可能的方法来调整αM？。 在这里，我们建议使用αM的调整？ 确保M中的所有训练实例满足最优条件（即约束（5））。 根据约束条件（5），我们有∀i∈I m和f i = b。 结合f i = b和f i的定义（参见方程（2）），对于每个i∈Im，我们有以下方程。
![](/images/media/15209562920278.jpg)

请注意，在上面的等式中y i可以省略。 我们可以用M的所有训练实例的矩阵符号重写方程（8）和方程（9）。

![](/images/media/15209934994110.jpg)

我们用ΔαT？ 和ΔαR？ 使用等式（7）; 上面的等式可以重写如下。

![](/images/media/15209935300906.jpg)

如果方程（10）中矩阵的逆不存在，我们找到伪逆（Greville，1960）。

计算步长eta：给定了步长eta，我们就可以用公式（7）和（10）来调整${\alpha\prime}_m$, ${\alpha\prime}_T$和${\alpha\prime}_R$。α值的变化导致所有最优性指标f的变化。 我们用Δf来表示对f的改变，这可以通过从等式（2）导出的以下等式来计算。

![](/images/media/15210096019190.jpg)

如果步长η太大，更多的最优性指标往往违反约束条件（5）。 在这里，我们使用方程（11）通过让更新后的fi（其中i∈Iu∪Il）刚好违反约束条件（5）来计算步长η，即fi +Δfi = b对于i∈Iu∪I l。

更新 f：在更新$\alpha\prime$之后，我们使用等式（2）和（11）更新f。 然后，根据约束（5）我们更新集合I m，I u和I l。

重复计算η和更新α和f的过程，直到R为空。

终止：当集合$R$为空时，SVM可能不是最优的，因为集合$T$可能不是空的。 从上述过程获得的阿尔法值作为下一个SVM的初始阿尔法值。 为了获得最佳SVM，我们使用SMO来调整初始alpha值，直到满足最优条件。 完整算法的伪代码显示在Wen等人的算法1中（2016）。


### 3.3 多样本替换优化方法
ATO的限制是它需要调整所有的α值，无限次（即直到R为空）。 因此，初始化alpha值的成本可能非常高。 接下来，我们提出只需调整一次αT的多实例替换（MIR）算法。 两轮之间的共享实例的α值保持不变（即αS =αS），直觉是许多支持向量倾向于保持不变。 MIR的关键思想是立即用T替换R.

我们从前一个SVM获得S和R中实例的alpha值，这些alpha值满足以下约束条件。
![](/images/media/15210107049056.jpg)

在下一轮SVM k-fold交叉验证中，删除R并添加T. 在重新使用alpha值时，我们应该保证上面的约束条件成立。 为了提高初始化alpha值的效率，我们在约束（12）的第一项中不改变alpha值。例如，![](/images/media/15210107515500.jpg)

为了满足上述约束条件，将$R$替换为T后，只需要确保r∈Iy rαr =t∈Iy tαt。 接下来，我们提出一种计算$\alpha\prime_T$的方法。

根据等式（2），我们可以在将$R$替换为$T$之前重写$f_i$，如下所示。
![](/images/media/15210112172036.jpg)

在用$T$代替$R$之后，可以如下计算$f_i$。
![](/images/media/15210113055653.jpg)

其中$\alpha\prime_s = \alpha_s$，即$S$中的$\alpha$值保持不变。我们可以通过从等式（14）中减去等式（13）来计算f i的变化，用Δfi表示。 然后，我们有下面的等式。
![](/images/media/15210162392650.jpg)

为了满足在用$\cal{T}$代替$\cal{R}$之后的约束y iαi = 0，我们有下面的等式。






### 3.4 单样本替换优化方法





## 参考文献

一个时间发生的概率大的时间信息熵比较小。

每个事件信息量的概率

信息熵能达到理论上最小的编码。

交叉熵
用错误的概率分布去衡量正确的熵

KL散度

交叉熵做 Loss Function，与 Sigmoid 的相比。

卷积特点

* 局部连接
* 共享权值
    * filter 的参数

Lenet

filter 的个数要怎么确定？调节

小 kernel size：
1. 参数少
2. 激活函数越多

AlexNet
层叠
1. 数据增强
2. dropout
3. lr decay

训练不起作用，测试再起作用。

VGGNet
小卷积
**MultiScale**，训练和测试都可以。

ResNet
越深效果越差。

恒等映射？



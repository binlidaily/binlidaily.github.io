---
layout: post
title: Dropout
subtitle: 丢弃法
author: Bin Li
tags: [Deep Learning, Regularization]
comments: true
published: true
---

　　Dropout (丢弃法) 是指在深度网络的训练中，以一定的概率随机地“临时丢弃”一部分神经元节点。具体来讲，Dropout 作用于每份小批量训练数据，由于其随机丢弃部分神经元的机制，相当于每次迭代都在训练不同结构的神经网络。

　　类比于 **Bagging** 方法，Dropout 可被认为是一种实用的大规模深度神经网络的**模型集成算法**。由于传统意义上的 Bagging 涉及多个模型的同时训练与测试评估，当网络与参数规模庞大时，这种集成方式需要消耗大量的运算时间与空间。Dropout 在小批量级别上的操作，提供了一种**轻量级的 Bagging 集成近似**，能够实现指数级数量神经网络的训练与评测。

　　Dropout 的具体实现中，要求某个神经元节点激活值以一定的概率 $p$ 被激活（$1-p$被丢弃，有的博文用 $p$ 表示舍弃概率，$1-p$ 作为保留概率，这里为了跟 keep_prob 保持一致，$p$ 取保留概率），即该神经元暂时停止工作，如下图所示。因此，对于包含 $N$ 个神经元节点的网络，在 Dropout 的作用下可看作为 $2^N$ 个模型的集成。这 $2^N$ 个模型可认为是原始网络的子网络，它们共享部分权值，并且具有相同的网络层数，而模型整体的参数数目不变，这就大大简化了运算。对于任意神经元，每次训练中都与一组随机挑选的不同的神经元集合共同进行优化，这个过程会减弱全体神经元之间的联合适应性，减少过拟合的风险，增强泛化能力。

<p align="center">
  <img width="500" height="" src="/img/media/15620738408794.jpg">
</p>

　　在神经网络中应用 Dropout 包括训练和预测两个阶段。在训练阶段中，每个神经元节点需要增加一个概率系数，如下图所示。**训练阶段**又分为前向传播和反向传播两个步骤。

<p align="center">
  <img width="500" height="" src="/img/media/15620741218791.jpg">
</p>

　　原始网络对应的前向传播公式为

$$
z_{i}^{(l+1)}=w_{i}^{(l+1)} y^{l}+b_{i}^{(l+1)}
$$

$$
y_{i}^{(l+1)}=f\left(z_{i}^{(l+1)}\right)
$$

　　应用 Dropout 之后，前向传播公式变为

$$
r_{j}^{(l)} \sim \text { Bernoulli }(p)
$$

$$
\tilde{y}^{(1)}=r^{(l) *} y^{(l)}
$$

$$
z_{i}^{(l+1)}=w_{i}^{(l+1)} \tilde{y}^{l}+b_{i}^{(l+1)}
$$

$$
y_{i}^{(l+1)}=f\left(z_{i}^{(l+1)}\right)
$$

　　上面的 Bernoulli 函数的作用是以概率系数 $p$ 随机生成一个取值为 $0$ 或 $1$ 的向量，代表每个神经元是否需要被丢弃。如果取值为 $0$，则该神经元将不会计算梯度或参与后面的误差传播。主要就是要得到每一层的 $r_{j}^{(l)}$ 序列，从而知道当前层那些神经元被舍弃了。

　　测试阶段是前向传播的过程。在前向传播的计算时，每个神经元的参数要预先乘以概率系数 $p$，以恢复在训练中该神经元只有 $p$ 的概率被用于整个神经网络的前向传播计算。


## Inverted Dropout
　　对最早的 Dropout 做了一点优化，提出了 Inverted Dropout。我们知道使用了Dropout 的输出为：

$$
a = px + (1-p)0
$$

　　也就是在训练的时候，留下来的神经元权重都乘以了权重 $p$，所以在预测的时候也需要对每个神经元的权重乘以该概率值。而一般来说再预测的时候，效率是比较重要的，所以我们要尽量减少这种乘法操作，那么可以使用 Inverted Dropout。我们只要在训练的时候，对每层已经通过 $r_{j}^{(l)}$ 筛选过的输出值 $a$ 除以 $p$ 即可，在测试时就不需要像最早的 Dropout 那样乘以 $p$ 了。

## References
1. [理解dropout](https://blog.csdn.net/stdcoutzyx/article/details/49022443)
2. 《百面机器学习》
3. [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/neural-networks-2/#reg)
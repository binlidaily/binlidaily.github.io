---
layout: post
title: Outline of Algorithms
subtitle:
author: Bin Li
bigimg: /img/media/algoritms.png
tags: [Outline]
comments: true
published: true
---

In order to facilitate the search, I wrote this blog. I've collected all algorithms that I learned or want to learn in `Machine Learning`, `Deep Learning`, `Mathematics` and `Data Structure and Algorithms`. I hope I can improve my skills and knowledge in these area with writing the interpretation about these algorithms. 

## 1. Theoretical Machine Learning
### 1.1 Supervised Learning
* [Linear Regression](https://binlidaily.github.io/2018-06-03-linear-regression/)
    * [Locally Weighted Linear Regression](https://binlidaily.github.io/2019-01-16-lwlr-locally-weighted-linear-regression/)
    * [Bayesian Linear Regression](https://binlidaily.github.io/2019-05-29-bayesian-linear-regression/)
    * [Polynomial Regression](https://binlidaily.github.io/2019-01-16-polynomial-regression/)
    * [Ridge and Lasso Regression](https://binlidaily.github.io/2019-01-16-ridge-lasso/)
    * ElasticNet

* [Logistic Regression](https://binlidaily.github.io/2017-10-03-logistics-regression/)
* [Decision Tree](https://binlidaily.github.io/2018-09-11-decision-tree/)
    - [Decision Stump](https://binlidaily.github.io/2019-06-04-decision-stump/)
    - [Iterative Dichotomiser 3 (ID3)](https://binlidaily.github.io/2019-06-04-id3-iterative-dichotomiser-3/)
    - [C4.5 and C5.0 (different versions of a powerful approach)](https://binlidaily.github.io/2019-06-04-C45/)
    * [Classification and Regression Tree (CART)](https://binlidaily.github.io/2019-06-04-cart-classification-and-regression-tree/)
    * [Adaboost](https://binlidaily.github.io/2018-10-29-adaboost/)
    * [Gradient Boosting](https://binlidaily.github.io/2018-12-05-gradient-boosting/)
    * [XGBoost](https://binlidaily.github.io/2018-10-29-xgboost/)
    * [Random Forest](https://binlidaily.github.io/2018-12-11-random-forest/)
    - Chi-squared Automatic Interaction Detection (CHAID)
    - M5
    - Conditional Decision Trees

* Perceptron
* [Neural Network](https://binlidaily.github.io/2018-10-29-neural-network/)
* Instance Based
    - K-Nearest Neighbor (KNN)
    - Learning Vector Quantization (LVQ)
    - Self-Organizing Map (SOM)
    - Locally Weighted Learning (LWL)

* Bayesian
    * [Naive Bayes](https://binlidaily.github.io/2019-05-09-naive-bayes/)
    - Gaussian Naive Bayes
    - Multinomial Naive Bayes
    - Averaged One-Dependence Estimators (AODE)
    - Bayesian Belief Network (BBN)
    - Bayesian Network (BN)
    - Hidden Markov Models
    - Conditional Random Fields (CRFs)

* [Linear Discriminant Analysis (LDA)](https://binlidaily.github.io/2018-08-30-linear-discriminant-analysis/)
* [Support Vector Machines](https://binlidaily.github.io/2019-01-10-support-vector-machines/)
* [Field-aware Factorization Machines (FFM)](https://binlidaily.github.io/2018-10-29-ffm-field-aware-factorization-machines/)

### 1.2 Unsupervised Learning
* Clustering
    * K-Means
    * K-Medians
    * Latent Dirichlet Allocation (LDA)
    * Single-linkage Clustering
    * Expectation Maximisation (EM)
    * Hierachical Clustering
    * Fuzzy Clustering
    * DBSCAN
    * OPTICS algorithm
    * Non-Negative Matrix Factorization


### 1.3 Ensemble Learning
- [Ensemble Learning](https://binlidaily.github.io/2019-02-08-ensembling-learning)
- Logit Boost (Boosting)
- Bootstrapped Aggregation (Bagging)
- AdaBoost
- Stacked Generalization (blending)
- Gradient Boosting Machines (GBM)
- Gradient Boosted Regression Trees (GBRT)
- Radom Forest


### 1.4 Models
*  Model Evaluation
    * [Bias and Variance](https://binlidaily.github.io/2019-01-16-bias-variance/)
    * [Loss Functions & Metrics](https://binlidaily.github.io/2018-12-07-loss-functions/)

* Model Selection
    * Model Selection


## 2. Applied Machine Learning
* [Workflow of Machine Learning](https://binlidaily.github.io/2019-02-25-workflow-of-applying-ml-algorithms-offline-to-online/) 

* [Feature Engineering](https://binlidaily.github.io/2018-06-03-feature-engineering/)
    * Feature Extraction
        * [Data Preprocessing](https://binlidaily.github.io/2018-11-13-data-preprocessing/)
        * [Exploratory Data Analysis (EDA)](https://binlidaily.github.io/2019-01-10-exploratory-data-analysis/)

    * Feature Selection
        * [Feature Selection Methods](https://binlidaily.github.io/2018-06-03-feature-engineering/)

* Model Ensemble
    * [Model Ensemble Methods](https://binlidaily.github.io/2019-02-08-ensembling/)


* Model Optimization
    * [Model Optimization Methods](https://binlidaily.github.io/2019-02-25-model-optimization/)
    * [Result Analysis](https://binlidaily.github.io/2019-02-11-explain-the-result-of-models/)
    * [Bad Case Analysis](https://binlidaily.github.io/2019-03-11-bad-case-analysis/)


* Applied Models
    * [Click Models](https://binlidaily.github.io/2019-02-25-click-models/)
    * [Ranking Algorithms](https://binlidaily.github.io/2019-01-23-ranking-algorithms/)

## 3. Deep Learning
* Computer Vision
    * Image Classification
        * [Convolutional Neural Networks (CNN)](https://binlidaily.github.io/2018-08-27-vgg-very-deep-convolutional-networks/)
        * [Very Deep Convolutional Networks (VGG)](https://binlidaily.github.io/2019-04-08-cnn-convolutional-neural-network/)

    * Object Detection
        * [Single Shot MultiBox Detector (SSD)](https://binlidaily.github.io/2019-01-19-single-shot-multibox-detector/)
    
    * Sequential Model
        * [Recurrent Neural Networks（RNN）](https://binlidaily.github.io/2019-04-12-rnn-recurrent-neural-network/)
        * [Long Short Term Memory networks（LSTM）](https://binlidaily.github.io/2019-04-12-lstm-long-short-term-memory-networks/)

* Speech Recognition
* 	Natural language processing
## 4. Mathematics
* Information Theory
    * [Entropy](https://binlidaily.github.io/2018-10-23-information-theory/)

* Optimization
    * [Gradient Descent](https://binlidaily.github.io/2018-04-24-gradient-descent/)
    * [Monte Carlo Method](https://binlidaily.github.io/2019-01-23-Monte-Carlo-method/)
    * [Singular Value Decomposition](https://binlidaily.github.io/2019-01-10-singular-value-decomposition/)
    * [Matrix Factorization](https://binlidaily.github.io/2019-01-10-matrix-factorization/)
    * [Newton Method](https://binlidaily.github.io/2018-12-27-newton-method/)

* Statistics
* [Normal Distribution](https://binlidaily.github.io/2019-01-23-normal-distribution/)


## References
1. [Sklearn User Guide](https://scikit-learn.org/stable/user_guide.html)
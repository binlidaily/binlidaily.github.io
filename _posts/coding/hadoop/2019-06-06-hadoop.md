---
layout: post
title: Learn Hadoop From Scratch
subtitle:
author: Bin Li
tags: [Coding]
image: 
comments: true
published: true
---

## Map-Reduce
　　把任务分成两个阶段，Map 阶段和 Reduce 阶段：
1. Map 阶段：通过 hash 函数把任务分成若干个子任务
2. Reduce 阶段：子任务并发处理，合并结果

　　难点是工程上的处理，注意点有：
1. 备份的考虑，分布式存储的设计细节，以及容灾策略
2. 任务分配策略与任务进度跟踪的细节设计，节点状态的呈现
3. 多用户权限的控制

### 海量数据处理
处理关键：
1. 分而治之。通过哈希函数将大人物分流到机器，或分流成小文件
2. 常用 hashmap 或 bitmap

难点：通讯、时间和空间的估算。

## HDFS 操作命令

```shell
# check files and folders in HDFS
hadoop fs -ls /
hadoop fs -mkdir /user
hadoop namenode -format
```


Since Hadoop 3.0.0 - Alpha 1 there was a Change in the port configuration:
```
http://localhost:50070
```

was moved to

```
http://localhost:9870
```

## 命令
```
jps
```

```
alias hstart="/usr/local/Cellar/hadoop/3.1.0_1/sbin/start-all.sh"
alias hstop="/usr/local/Cellar/hadoop/3.1.0_1/sbin/stop-all.sh"
```

需要 sudo 权限才行……


```python
# 启动服务
$HADOOP_HOME/sbin/start-all.sh

# 启动 pyspark
pyspark
## 如果想用 jupyter notebook 形式启动
## 先在 terminal 上运行以下命令，或者加到 ~/.bashrc or ~/.zshrc 文件中一劳永逸解决
export PYSPARK_DRIVER_PYTHON=jupyter
export PYSPARK_DRIVER_PYTHON_OPTS='notebook'
## 然后运行 pyspark
```

## YARN

## Kafka

## Hive

## Storm

## 问题总结

### 拒绝连接
```
cal/192.168.31.91 to localhost:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
```


```
Stop it by-: stop-all.sh
format the namenode-: hadoop namenode -format
again start-: start-all.sh
```

## References
1. [Hadoop安装教程_单机/伪分布式配置_Hadoop2.6.0/Ubuntu14.04](http://dblab.xmu.edu.cn/blog/install-hadoop/)
2. [学习Spark——环境搭建（Mac版）](https://www.cnblogs.com/bigdataZJ/p/hellospark.html)
3. [Hadoop 3.1.1 Mac OS Namenode Issues](https://stackoverflow.com/questions/52750030/hadoop-3-1-1-mac-os-namenode-issues/53041538)
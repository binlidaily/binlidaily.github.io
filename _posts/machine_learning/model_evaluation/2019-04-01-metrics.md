---
layout: post
title:  Metrics
subtitle: 性能度量
author: Bin Li
tags: [Machine Learning]
image: 
comments: true
published: true
---


## 准确率（Accuracy）
　　准确率是指**分类**正确的样本占总样本个数的比例：

$$
\text{Accuracy}=\frac{n_\text{correct}}{n_\text{total}}
$$

　　准确率是分类问题中最简单也最直观的评价指标，但是也有明显的缺陷。比如，当负样本当负样本占 99% 时，分类器把所有样本都预测为负样本也可以获得 99% 的准确率。所以，当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。

　　为了解决这个问题，可采用更为有效的平均准确率（每个类别下的样本准确率的算术平均）作为模型评估的指标。

## 查准率（Precision）与查全率（Recall）

## KL 散度（Kullback-Leibler Divergence）
　　KL 散度（相对熵），是一种**量化两种概率分布 P 和 Q 之间差异的方式**，又叫相对熵。在概率学和统计学上，我们经常会使用一种更简单的、近似的分布来替代观察数据或太复杂的分布。K-L散度能帮助我们度量使用一个分布来近似另一个分布时所损失的信息。

$$
D_{K L}(p(x) \| q(x))=\sum_{x \in X} p(x) \ln \frac{p(x)}{q(x)}
$$


## TODO
目标检测
* mAP
* 协方差


## References
1. [如何理解K-L散度（相对熵）](https://www.jianshu.com/p/43318a3dc715)
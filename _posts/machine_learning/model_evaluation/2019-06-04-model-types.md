---
layout: post
title: Types of Model
subtitle: 模型分类
author: Bin Li
tags: [Machine Learning]
image: 
comments: true
published: true
---

## 生成模型和判别模型
![](/img/media/15607792534960.jpg)

　　监督学习方法可以分为生成方法 (Generative Approach) 和判别方法 (Discriminative Approach)，对应生成的模型就是生成模型和判别模型。

* 生成模型
    * 生成模型想要得到某个关于输入是如何产生输出的“构造性模型”，尝试建模数据的生成过程。
    * 优点
        * 可以还原联合概率分布？
        * 学习收敛速度更快，当样本增加时，也能更快地收敛
        * 当存在隐变量时也能用
    * 举例
        * 朴素贝叶斯
        * 隐马尔科夫模型
* 判别模型
    * 判别模型则更强调结果的准确度，直接由数据学习目标函数，不必知道某种类别是如何产生输入实例的。
    * 优点
        * 因为直接从数据中学习，直面预测，所以准确率更高
        * 也因此可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题
    * 举例
        * k 近邻、感知机、决策树、逻辑斯特回归、最大上模型、支持向量机、提升方法、条件随机场


其实机器学习的任务是从属性X预测标记Y，即求概率P(Y|X)；

对于判别式模型来说求得P(Y|X)，对未见示例X，根据P(Y|X)可以求得标记Y，即可以直接判别出来，如上图的左边所示，实际是就是直接得到了判别边界，所以传统的、耳熟能详的机器学习算法如线性回归模型、支持向量机SVM等都是判别式模型，这些模型的特点都是输入属性X可以直接得到Y（对于二分类任务来说，实际得到一个score，当score大于threshold时则为正类，否则为反类）~（根本原因个人认为是对于某示例X_1，对正例和反例的标记的条件概率之和等于1，即P(Y_1|X_1)+P(Y_2|X_1)=1）

而生成式模型求得P(Y,X)，对于未见示例X，你要求出X与不同标记之间的联合概率分布，然后大的获胜，如上图右边所示，并没有什么边界存在，对于未见示例（红三角），求两个联合概率分布（有两个类），比较一下，取那个大的。机器学习中朴素贝叶斯模型、隐马尔可夫模型HMM等都是生成式模型，熟悉Naive Bayes的都知道，对于输入X，需要求出好几个联合概率，然后较大的那个就是预测结果~根本原因个人认为是对于某示例X_1，对正例和反例的标记的联合概率不等于1，即P(Y_1,X_1)+P(Y_2,X_1)<1，要遍历所有的X和Y的联合概率求和，即sum(P(X,Y))=1，具体可参见楼上woodyhui提到的维基百科Generative model里的例子）



无论是生成式模型还是判别式模型，都可作为分类器使用，分类器的数学表达即为：给定输入 $X$ 以及分类变量 $Y$，求 $P(Y\vert X)$。

判别式模型直接估算 $P(Y\vert X)$，或者也可像 SVM 那样，估算出输入和输出之间的映射，与概率无关；

判别式模型的典型代表是：logistic 回归；
产生式模型的思想是先估计联合概率密度 $P(X,Y)$，再通过贝叶斯公式求出 $P(Y\vert X)$；

生成式模型的典型代表则是：朴素贝叶斯模型；

一般认为判别式模型更受欢迎，“人们更应该直接去解决问题，永远不要把求解更复杂的问题作为中间阶段”（Vapnik），Andrew Ng 的论文[1]对此作了较为全面的分析，产生式模型（朴素贝叶斯）在少量样本的情况下，可以取得更好的精确率，判别式模型（logistics 回归）在样本增加的情况下，逐渐逼近前者的概率；

这里有人会问，那为什么它是一个生成模型呢？简而言之，我们首先有一个类，也有这个类的y的先验概率分布，并且知道这个类的分布类型是伯努利分布。那么生成过程就是（1）从伯努利分布的类中抽样。 （2）基于类标签，我们从相应的分布中抽取x。这便是一个生成过程。

## 参数方法（parameter）与非参数方法（nonparameter）
参数方法表示参数固定，不随数据点的变化而变化； 
非参数方法并不意味着没有参数，而是说，参数的数目随数据点而变化，

**1. 参数方法举例**
logistic regression：p(y=1|x,α)=11+exp(−xTα)p(y=1|x,α)=11+exp⁡(−xTα)，显然参数，αα 的维数会随着数据集属性列个数的变化而变化，而不会随着数据规模的变化而变化；

**2. 非参数方法举例**
Nearest-Neighbor：比如一个二分类问题，新来一个测试点，当要计算其所属类别时，需要与全部训练集计算距离；

## References
1. [生成式模型（generative） vs 判别式模型（discriminative）](https://blog.csdn.net/lanchunhui/article/details/60321358)
2. [机器学习“判定模型”和“生成模型”有什么区别？](https://www.zhihu.com/question/20446337/answer/256466823)
3. [参数方法（parameter）与非参数方法（nonparameter）](https://blog.csdn.net/lanchunhui/article/details/53574727)
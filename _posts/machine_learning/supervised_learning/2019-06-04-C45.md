---
layout: post
title: C4.5
subtitle:
author: Bin Li
tags: [Machine Learning]
image: 
comments: true
published: true
---

　　C4.5 算法生成决策树的一种经典算法，是 [ID3]([](http://gitlinux.net/2019-06-04-id3-iterative-dichotomiser-3/)) 的优化版本，主要进行了一下几个方面的优化：
1. 通过信息[增益率](http://gitlinux.net/2018-09-11-decision-tree/#112-增益率gain-ratio)选择分裂属性，克服了ID3算法中通过信息增益倾向于选择拥有多个属性值的属性作为分裂属性的不足；
2. 能够处理离散型和连续型的属性类型，即将连续型的属性进行[离散化处理](http://gitlinux.net/2018-09-11-decision-tree/#21-连续值处理)；
    * C4.5 处理连续特征是先将特征取值排序，以连续两个值中间值作为划分标准。
    * 尝试每一种划分，并计算修正后的信息增益，选择信息增益比最大的分裂点作为该属性的分裂点。
3. 构造决策树之后进行剪枝操作；
4. 能够处理具有缺失属性值的训练数据。

## C4.5 剪枝
　　C4.5 生成的决策树也有过拟合的倾向，需要进行剪枝。

C4.5 **优点**： 
1. 通过信息增益率选择分裂属性，克服了 ID3 算法中通过信息增益倾向于选择拥有多个属性值的属性作为分裂属性的不足； 
2. 能够处理离散型和连续型的属性类型，即将连续型的属性进行离散化处理； 
3. 构造决策树之后进行剪枝操作，减少了过拟合现象； 
4. 能够处理具有缺失属性值的训练数据。

C4.5 **缺点**： 
1. 算法的计算效率较低，特别是针对含有连续属性值的训练样本时表现的尤为突出。 
2. 算法在选择分裂属性时没有考虑到条件属性间的相关性，只计算数据集中每一个条件属性与决策属性之间的期望信息，有可能影响到属性选择的正确性。


## References
1. [决策树之C4.5算法详解](https://blog.csdn.net/zhihua_oba/article/details/70632622)
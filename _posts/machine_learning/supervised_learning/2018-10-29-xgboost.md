---
layout: post
title: Xgboost
subtitle:
author: Bin Li
tags: [Machine Learning]
image: 
comments: true
published: true
---

XGBoost 算法是在 CART 基础上对 Boosting 算法的一个改进，CART 内部决策树选定回归树。由于 Boosting 算法在损失函数选择时有较大区别，例如如果选择平方损失函数，就是 Boosting Tree 的方式，那么需要拟合残差。而对于使用一般损失函数而言，则可以采用 Gradient Boosting 的方式，根据梯度下降来拟合残差的近似值。



## Prerequisites
回顾一下，当我们谈及决策树的时候，其实它是启发式的，但是这些启发式的操作却有对应的意义：
* 根据信息增益划分属性 ➡️ 降低训练误差
* 剪枝 ➡️ 可以看成通过节点数定义的归一化方式
* 最大深度 ➡️ 在函数空间上的约束条件
* 平滑叶节点取值平滑 ➡️ 实际是叶节点权重的 L2 归一化

回归树不光可以做回归，主要看你如何利用预测结果，实际上可以用来做：分类、回归和排名等。主要依赖于你怎么定义目标函数，像之前用平方误差就构成了最基本的 Gradient Boosting 方法，我们可以总结如下：

![-w1123](/img/media/15456354000624.jpg)

类似地，我们在考虑一个模型的目标函数时，强调有两个部分：

$$
{ Obj } ( \Theta ) = L ( \Theta ) + \Omega ( \Theta )
$$

$L ( \Theta )$ 代表损失函数的部分，衡量模型在训练集上拟合的好坏程度；$\Omega ( \Theta )$ 代表正则化部分，衡量模型的复杂度。

基于此，我们再回顾一下针对加法模型的训练，第 $t$ 轮的预测值为：



![-w1059](/img/media/15458114911214.jpg)

其中的等式转换把一些常量省去了。

## XGBoost 算法
在前面我们可以看到，损失函数的选取对 Gradient Boosting 方法来说有较大的影响。而对于除了平方误差的损失函数，其他损失函数处理起来依然很是复杂，于是陈天奇就想出了利用**泰勒展开来拟合目标函数**的方法。

模型训练的目标函数是：

$$
O b j ^ { ( t ) } = \sum _ { i = 1 } ^ { n } l \left( y _ { i } , \hat { y } _ { i } ^ { ( t - 1 ) } + f _ { t } \left( x _ { i } \right) \right) + \Omega \left( f _ { t } \right) + \text { constant }
$$

对目标函数的二阶泰勒展开式：

$$
f ( x + \Delta x ) \simeq f ( x ) + f ^ { \prime } ( x ) \Delta x + \frac { 1 } { 2 } f ^ { \prime \prime } ( x ) \Delta x ^ { 2 }
$$

其中定义

$$g _ { i } = \partial _ { \hat { y } ^ { ( t - 1 ) } } l \left( y _ { i } , \hat { y } ^ { ( t - 1 ) } \right)$$

$$h _ { i } = \partial _ { \hat { y } ^ { ( t - 1 ) } } ^ { 2 } l \left( y _ { i } , \hat { y } ^ { ( t - 1 ) } \right)$$

那么目标函数就转换成了：

$$
O b j ^ { ( t ) } \simeq \sum _ { i = 1 } ^ { n } \left[ l \left( y _ { i } , \hat { y } _ { i } ^ { ( t - 1 ) } \right) + g _ { i } f _ { t } \left( x _ { i } \right) + \frac { 1 } { 2 } h _ { i } f _ { t } ^ { 2 } \left( x _ { i } \right) \right] + \Omega \left( f _ { t } \right) + \text { constant }
$$

这也是 XGBoost 运行快的一个原因，近似求解总是会好的。

举个特例来看一下，假设损失函数 $l$ 用的是平方误差可以得到：

$$
g _ { i } = \partial _ { \hat { y } ^ { ( t - 1 ) } } \left( \hat { y } ^ { ( t - 1 ) } - y _ { i } \right) ^ { 2 } = 2 \left( \hat { y } ^ { ( t - 1 ) } - y _ { i } \right)
$$

$$
h _ { i } = \partial _ { \hat { y } ^ { ( t - 1 ) } } ^ { 2 } \left( y _ { i } - \hat { y } ^ { ( t - 1 ) } \right) ^ { 2 } = 2
$$

代入目标函数之后跟前面提到的结果一致。

那么问题来了，为什么要这么操作？陈天奇从理论和实践总结了两个方面的原因：
* Theoretical benefit: 知道我们具体在学习什么以及模型收敛情况。
* Engineering benefit: 从监督学习方面理解
    * $g _ { i }$ 和 $h _ { i }$ 都来自于损失函数，且学习过程中只跟这两项有关
    * 这种学习方式有利于在大规模并行化上的实现

至此，我们已经明确了第 $t$ 轮训练的目标 $Obj^{(t)}$：

$$
\sum _ { i = 1 } ^ { n } \left[ g _ { i } f _ { t } \left( x _ { i } \right) + \frac { 1 } { 2 } h _ { i } f _ { t } ^ { 2 } \left( x _ { i } \right) \right] + \Omega \left( f _ { t } \right)
$$

其中，$g _ { i } = \partial _ { \hat { y } ^ { ( t - 1 ) } } l \left( y _ { i } , \hat { y } ^ { ( t - 1 ) } \right)$，$h _ { i } = \partial _ { \hat { y } ^ { ( t - 1 ) } } ^ { 2 } l \left( y _ { i } , \hat { y } ^ { ( t - 1 ) } \right)$。

接下来就应该讨论如何训练具体的 $f_t(x)$，为此我们在数学上重新定义树：

$$
f _ { t } ( x ) = w _ { q ( x ) } , \quad w \in \mathbf { R } ^ { T } , \quad q : \mathbf { R } ^ { d } \rightarrow \{ 1,2 , \cdots , T \}
$$

我们通过两个部分来重新定义树：
1. XGBoost 给每一个叶子节点一个得分 $w_i$，第一部分就是这些所有叶节点得分组成的一个向量
2. 一个从样本到叶节点下标的映射函数 $q(x)$，输入一个样本点从而得到对应的该划分到的叶节点，即 $q(x)$ 便是该树的结构

$q(\mbox{x})$ 表示将样本 $\mbox{x}$ 分到了某个叶子节点上， $w$ 是叶子节点的分数 (leaf score)，所以 $w_{q(\mbox{x})}$ 表示回归树对样本的预测值。

![-w1311](/img/media/15458896195390.jpg)

根据树的定义，我们顺势可以定义一下树的复杂度（不唯一）：
![-w804](/img/media/15458916251117.jpg)

基于上述树的定义和复杂度的定义，我们重新改写目标函数。首先按照如下定义叶节点中的样本集：

![-w312](/img/media/15458920420813.jpg)

接着将复杂度的定义代入到目标函数中：

![-w1049](/img/media/15458919820966.jpg)

那么目标函数就转换成了有关 $w_j$ 的一元二次函数，那么当 $H>0$，找到对称轴，计算出最小值，可以按照如下方式找到目标函数的极值。

![-w1248](/img/media/15458925856802.jpg)

此时的 $Obj$ 就可以用来衡量一棵树结构的好坏程度，其值越小，这个结构就越好。

那么，对于不同的划分能够得到不同的树结构，如此该如何划分才更合适？即要如何找到树的结构？

* 暴力枚举所有可能的树结构，选择损失值最小的-NP难问题；
* 贪心法：每次尝试分裂一个叶节点，计算分裂前后的增益，选择增益最大的；

整理一下选择增益的计算方式：

* ID3算法：信息增益；
* C4.5算法：信息增益比；
* CART算法：Gini 系数；
* XGBoost：打分函数（类似于信息增益方式：$\color{red}{Gain_{split\_before} - Gain_{split\_after}}$ ）；


![-w1300](/img/media/15458962970070.jpg)

在计算 $Gain$ 时，就是拿拆分后的 $Obj$ 值与拆分前的比较其差值。

![-w1284](/img/media/15458963064823.jpg)

那么在划分的时候就找到那些能够使得 Gain 的得分最多的划分。

⁉️ Line Search 是啥？

用 Newton boosting 来估算新的叶节点的值？

![](/img/media/15459635552193.png)


先选定一个损失函数，

## References
1. [Boosted Tree by Tianqi Chen](https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf)
2. [Loss function Approximation With Taylor Expansion](https://stats.stackexchange.com/questions/202858/loss-function-approximation-with-taylor-expansion)
3. [Tree Boosting With XGBoost](https://brage.bibsys.no/xmlui/bitstream/handle/11250/2433761/16128_FULLTEXT.pdf)
4. [Introduction to Boosted Trees](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)
5. [Newton Boosting Tree 算法原理：详解 XGBoost](https://zhuanlan.zhihu.com/p/38297689)
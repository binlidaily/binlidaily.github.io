---
layout: post
title: Stacking
subtitle: 
author: Bin Li
tags: [Machine Learning]
image: 
comments: true
published: true
typora-root-url: ../../../../../binlidaily.github.io
typora-copy-images-to: ../../../../img/media
---

　　Stacking 是先用全部数据训练好基模型，然后每个基模型都对每个训练样本进行的预测，其预测值将作为训练样本的特征值，最终会得到新的训练样本，然后基于新的训练样本进行训练得到模型，然后得到最终预测结果。

　　Stacking (Stacked Generalization) 是一种使用串行的组合基学习器的方法，之前的方法都是采用多数投票或者平均的方式做组合策略，那么何不利用训练一个模型的方式做结果组合？Stacking 就采用这种想法，把前一个基学习器 (Base-learner) 的结果**作为特征**输出到下一个学习器 (Meta-learner)，最后的学习器作为融合模型进行最后结果的预测。

<p align="center">
<img width="500" src="./img/media/15620593061827.jpg">
</p>


　　Meta-learner 的选取有很多，可以是常见的 Voting，也可以是容易解释的算法如 LR 等，具体可[参考](https://blog.csdn.net/g11d111/article/details/80215381)。Stacking 实践可以用 [mlxtend](https://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/) 的工具。

　　代码实现[参考](https://github.com/ageron/handson-ml/blob/master/07_ensemble_learning_and_random_forests.ipynb)，整理！
## References
1. 《Hands-On Machine Learning》